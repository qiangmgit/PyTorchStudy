{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy6UAIPXu2YR"
      },
      "source": [
        "Test if image exists\n",
        "First, download https://github.com/falloutdurham/beginners-pytorch-deep-learning/tree/master/chapter2 and run download.py in that directory(some of them won't be downloaded successfully, which shouldn't matter).\n",
        "Then, upload train & test & val folders to Google Drive. Finally, in Colab Notebooks, mount Google Drive in the Files Menu on the left.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi9TQVfVT4ln"
      },
      "source": [
        "Note, in this notebook, in Runtime, select \"Run all\" is almost always needed, as much of the code relies on the result from previous python running."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNMpfcXPR50i"
      },
      "source": [
        "Firstly, mount Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T0IREtoR4jt",
        "outputId": "390c2926-8ac9-4c10-cc14-b5b639800686"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDgpvLHMtgYj",
        "outputId": "35d4f8a6-c694-49fa-d0cb-e3a61ead83a0"
      },
      "source": [
        "# PIL is a widely used python image library\n",
        "import PIL\n",
        "from PIL import Image, ImageFile\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# this is to prevent image file to be too large\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
        "\n",
        "workspace_path = \"./drive/MyDrive/image_classification_test/\"\n",
        "train_data_path = workspace_path + \"/train/\"\n",
        "val_data_path = workspace_path + \"/val/\"\n",
        "test_data_path = workspace_path + \"/test/\"\n",
        "\n",
        "# check if this image exists\n",
        "img = Image.open(val_data_path + \"/fish/100_1422.JPG\")\n",
        "print(img.size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 342)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bvq4A8YIHiu"
      },
      "source": [
        "Run the following to set train_data, test_data and validation_data. The torchvision helps do the image preprocessing here.\n",
        "Search for knowledge about train set, test set and validation set if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xTTopiAIiFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf80cda-1fea-4460-c6eb-8dfcdafaac48"
      },
      "source": [
        "# this function is very important, otherwise quite a few images won't be opened successfully, causing script's runtime error.\n",
        "def check_image(path):\n",
        "  try:\n",
        "    Image.open(path)\n",
        "    return True\n",
        "  except:\n",
        "    return False\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "    transforms.Resize((64, 64)), # resize image\n",
        "    transforms.ToTensor(), # store image data in tensor\n",
        "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
        "    # the above normalization follows distribution of ImageNet dataset\n",
        "    ])\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform = img_transforms, is_valid_file=check_image)\n",
        "\n",
        "val_data = torchvision.datasets.ImageFolder(root = val_data_path, transform = img_transforms, is_valid_file=check_image)\n",
        "\n",
        "test_data = torchvision.datasets.ImageFolder(root = test_data_path, transform = img_transforms, is_valid_file=check_image)\n",
        "\n",
        "# load data in a batch\n",
        "batch_size = 64\n",
        "train_data_loader = data.DataLoader(train_data, batch_size = batch_size)\n",
        "val_data_loader = data.DataLoader(val_data, batch_size = batch_size)\n",
        "test_data_loader = data.DataLoader(test_data, batch_size = batch_size)\n",
        "# check how many images get loaded\n",
        "print(len(train_data_loader.dataset))\n",
        "print(len(val_data_loader.dataset))\n",
        "print(len(test_data_loader.dataset))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "803\n",
            "110\n",
            "160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuHQtLTJHdJN"
      },
      "source": [
        "Define the network structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ5rE7HdHgnN",
        "outputId": "21842b1b-3cbf-4c6f-c616-70800b2de591"
      },
      "source": [
        "class simple_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(simple_net, self).__init__()\n",
        "        # search for the definition of nn.Linear for more info\n",
        "        # 12288 is for 64 * 64 * 3 (image size)\n",
        "        self.fc1 = nn.Linear(12288, 84)\n",
        "        self.fc2 = nn.Linear(84, 50)\n",
        "        self.fc3 = nn.Linear(50, 2)\n",
        "    # search for the definition of forward for more info\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 12288)\n",
        "        # search for why relu is used in neural networks\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "my_model = simple_net()\n",
        "# search for Adam optimizer for more info if needed\n",
        "optimizer = optim.Adam(my_model.parameters(), lr = 0.001)\n",
        "\n",
        "# copy the model to device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "my_model.to(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "simple_net(\n",
              "  (fc1): Linear(in_features=12288, out_features=84, bias=True)\n",
              "  (fc2): Linear(in_features=84, out_features=50, bias=True)\n",
              "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5dL-TLX5K_G"
      },
      "source": [
        "Note the following code relies on result from previous python running. Click on the \"Runtime\" and select \"Run all\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m89G9MrK5ba2"
      },
      "source": [
        "Train the model and print the loss result per epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5DE4zD95ZbH",
        "outputId": "c25fd0fc-2981-439e-effa-e0c8e8e71227"
      },
      "source": [
        "def loss_update(model, batch, loss_fn, device, check_result):\n",
        "    inputs, targets = batch\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    output = model(inputs)\n",
        "    loss = loss_fn(output, targets)\n",
        "    num_current_correct = 0\n",
        "    if (check_result):\n",
        "        result = torch.eq(torch.max(F.softmax(output, dim = 1), dim = 1)[1], targets)\n",
        "        num_current_correct = torch.sum(result).item()\n",
        "    return loss, num_current_correct\n",
        "\n",
        "def train(model, optimizer, loss_fn, train_data_loader, val_data_loader, epochs, device):\n",
        "  for epoch in range(epochs):\n",
        "    training_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    # this is to set model in training mode\n",
        "    model.train()\n",
        "    check_result = False\n",
        "    # training process\n",
        "    for batch in train_data_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = loss_update(model, batch, loss_fn, device, check_result)[0]\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      training_loss += loss.data.item() * batch[0].shape[0]\n",
        "    training_loss /= len(train_data_loader.dataset)\n",
        "\n",
        "    # this is to set model in evaluation mode\n",
        "    model.eval()\n",
        "    check_result = True\n",
        "    num_correct = 0\n",
        "    num_examples = 0\n",
        "    for batch in val_data_loader:\n",
        "      loss, num_current_correct= loss_update(model, batch, loss_fn, device, check_result)\n",
        "      valid_loss += loss.data.item() * batch[0].shape[0]\n",
        "      num_correct += num_current_correct\n",
        "      num_examples += batch[0].shape[0]\n",
        "    valid_loss /= len(val_data_loader.dataset)\n",
        "\n",
        "    print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss, valid_loss, num_correct / num_examples))\n",
        "\n",
        "# modify the number of epochs to check how loss and accuracy changes with more training\n",
        "train(my_model, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, val_data_loader, 20, device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Training Loss: 3.74, Validation Loss: 2.82, accuracy = 0.40\n",
            "Epoch: 1, Training Loss: 2.02, Validation Loss: 1.38, accuracy = 0.43\n",
            "Epoch: 2, Training Loss: 1.28, Validation Loss: 0.82, accuracy = 0.71\n",
            "Epoch: 3, Training Loss: 0.64, Validation Loss: 0.65, accuracy = 0.70\n",
            "Epoch: 4, Training Loss: 0.43, Validation Loss: 0.69, accuracy = 0.67\n",
            "Epoch: 5, Training Loss: 0.40, Validation Loss: 0.63, accuracy = 0.75\n",
            "Epoch: 6, Training Loss: 0.29, Validation Loss: 0.66, accuracy = 0.69\n",
            "Epoch: 7, Training Loss: 0.28, Validation Loss: 0.65, accuracy = 0.73\n",
            "Epoch: 8, Training Loss: 0.24, Validation Loss: 0.63, accuracy = 0.72\n",
            "Epoch: 9, Training Loss: 0.20, Validation Loss: 0.66, accuracy = 0.70\n",
            "Epoch: 10, Training Loss: 0.18, Validation Loss: 0.65, accuracy = 0.72\n",
            "Epoch: 11, Training Loss: 0.17, Validation Loss: 0.66, accuracy = 0.72\n",
            "Epoch: 12, Training Loss: 0.14, Validation Loss: 0.66, accuracy = 0.73\n",
            "Epoch: 13, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.71\n",
            "Epoch: 14, Training Loss: 0.11, Validation Loss: 0.68, accuracy = 0.72\n",
            "Epoch: 15, Training Loss: 0.10, Validation Loss: 0.70, accuracy = 0.69\n",
            "Epoch: 16, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.72\n",
            "Epoch: 17, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.71\n",
            "Epoch: 18, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.71\n",
            "Epoch: 19, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pblLPIpETtT_"
      },
      "source": [
        "After training, run prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMEErtk6Twm_",
        "outputId": "115f8f61-6531-4fd9-de29-3c1bf45358b8"
      },
      "source": [
        "labels = ['cat', 'fish']\n",
        "img = Image.open(val_data_path + \"/fish/100_1422.JPG\")\n",
        "img = img_transforms(img).to(device)\n",
        "img = torch.unsqueeze(img, 0)\n",
        "my_model.eval()\n",
        "prediction = F.softmax(my_model(img), dim = 1)\n",
        "print(\"prediction = \")\n",
        "print(prediction)\n",
        "prediction = prediction.argmax()\n",
        "print(labels[prediction])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction = \n",
            "tensor([[9.2736e-06, 9.9999e-01]], grad_fn=<SoftmaxBackward>)\n",
            "fish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywMF1XjSrEwR"
      },
      "source": [
        "Run the following to save model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez29USsDrLQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d1b650-3704-46eb-9ed6-dd23bf8be69f"
      },
      "source": [
        "model_path = workspace_path + \"/simple_net.pth\"\n",
        "torch.save(my_model, model_path)\n",
        "# reload\n",
        "my_model = torch.load(model_path)\n",
        "\n",
        "# only save the parameters\n",
        "model_dict_path = workspace_path + \"/simple_net_dict.pth\"\n",
        "torch.save(my_model.state_dict(), model_dict_path)\n",
        "my_model = simple_net()\n",
        "my_model_state_dict = torch.load(model_dict_path)\n",
        "my_model.load_state_dict(my_model_state_dict)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}